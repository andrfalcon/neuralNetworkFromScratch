{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9e5eb107-d2ee-485a-8ebf-c7f02b3dd737",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import mnist_loader\n",
    "\n",
    "training_data, validation_data, test_data = mnist_loader.load_data_wrapper()\n",
    "training_data, test_data = list(training_data), list(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88375334-e4b0-4611-bc90-4a361ca6c40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    # sizes = [5, 3, 2]\n",
    "    def __init__(self, sizes):\n",
    "        self.sizes = sizes\n",
    "        self.weights = [np.random.randn(sizes[i], sizes[i-1]) for i in range(1, len(sizes))]\n",
    "        self.biases = [np.random.randn(i, 1) for i in sizes[1:]]\n",
    "\n",
    "    def feed_forward(self, a):\n",
    "        a_s, z_s = [a], []\n",
    "        for W, b in zip(self.weights, self.biases):\n",
    "            z = (W @ a) + b\n",
    "            z_s.append(z)\n",
    "            a = self.sigmoid(z)\n",
    "            a_s.append(a)\n",
    "        return (a_s, z_s, a)\n",
    "            \n",
    "    def back_propogation(self, y, a_s, z_s):\n",
    "        deltas = [0 for _ in range(len(self.sizes) - 1)]\n",
    "        delta_L = (a_s[-1] - y) * self.sigmoid_prime(z_s[-1])\n",
    "        deltas[-1] = delta_L\n",
    "        \n",
    "        for l in reversed(range(len(a_s)-2)):\n",
    "            delta_l = (self.weights[l+1].T @ deltas[l+1]) * self.sigmoid_prime(z_s[l])\n",
    "            deltas[l] = delta_l\n",
    "\n",
    "        nabla_b = deltas\n",
    "        nabla_w = [deltas[i] @ (a_s[i]).T for i in range(len(a_s) - 1)]\n",
    "\n",
    "        return (nabla_w, nabla_b)\n",
    "\n",
    "    def gradient_descent(self, w_gradients, b_gradients, eta):\n",
    "        for i in range(len(self.weights)):\n",
    "            self.weights[i] = self.weights[i] - (eta * w_gradients[i+1][0])\n",
    "            self.biases[i] = self.biases[i] - (eta * b_gradients[i+1][0])\n",
    "                        \n",
    "    def train(self, epochs, training_data, eta):\n",
    "        for i in range(epochs):\n",
    "            w_gradients, b_gradients = {i:[] for i in range(1, len(self.sizes))}, {i:[] for i in range(1, len(self.sizes))}\n",
    "            for j in training_data:\n",
    "                a_s, z_s, y_hat = self.feed_forward(j[0])\n",
    "                nabla_w, nabla_b = self.back_propogation(j[1], a_s, z_s)\n",
    "                for i in range(len(nabla_w)):\n",
    "                    w_gradients[i+1].append(nabla_w[i])\n",
    "                    b_gradients[i+1].append(nabla_b[i])\n",
    "            # Compute the average\n",
    "            for j in w_gradients.keys():\n",
    "                avg = np.mean(np.stack(w_gradients[j]), axis=0)\n",
    "                w_gradients[j] = avg\n",
    "\n",
    "            for j in b_gradients.keys():\n",
    "                avg = np.mean(np.stack(b_gradients[j]), axis=0)\n",
    "                b_gradients[j] = avg\n",
    "                \n",
    "            # Perform gradient descent\n",
    "            self.gradient_descent(w_gradients, b_gradients, eta)\n",
    "            print(i)\n",
    "                    \n",
    "    def sigmoid(self, k):\n",
    "        return 1.0 / (1.0 + np.exp(-k))\n",
    "\n",
    "    def sigmoid_prime(self, z):\n",
    "        return self.sigmoid(z)*(1-self.sigmoid(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "adb472c3-83ed-43aa-87af-06e3580a1680",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, sizes):\n",
    "        self.sizes = sizes\n",
    "        self.weights = [np.random.randn(sizes[i], sizes[i-1]) for i in range(1, len(sizes))]\n",
    "        self.biases = [np.random.randn(i, 1) for i in sizes[1:]]\n",
    "\n",
    "    def feed_forward(self, a):\n",
    "        a_s = [a]\n",
    "        z_s = []\n",
    "        for i in range(len(weights)): # note: len(weights) = len(biases)\n",
    "            z = (self.weights[i] @ a) + self.biases[i]\n",
    "            z_s.append(z)\n",
    "            a = self.sigmoid(z)\n",
    "            a_s.append(a)\n",
    "\n",
    "        return (a_s, z_s)\n",
    "        \n",
    "\n",
    "    def stochastic_gradient_descent(self, training_data, epochs, eta, batch_size):\n",
    "        for i in range(epochs):\n",
    "            random.shuffle(training_data)\n",
    "            mini_batches = [training_data[j:j+batch_size] for j in range(0, len(training_data), batch_size)]\n",
    "            for mini_batch in mini_batches:\n",
    "                nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "                nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "                for x, y in mini_batch:\n",
    "                    delta_nabla_w, delta_nabla_b = self.backpropagate(x, y)\n",
    "                    nabla_w = [nw + dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]\n",
    "                    nabla_b = [nb + dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]\n",
    "\n",
    "                self.weights = [w - ((eta / len(mini_batch)) * nw) for w, nw in zip(self.weights, nabla_w)]\n",
    "                self.biases = [b - ((eta / len(mini_batch)) * nb) for b, nb in zip(self.biases, nabla_b)]\n",
    "                \n",
    "            print(f'Epoch {i+1}/{epochs} completed.')\n",
    "\n",
    "    def backpropagate(self, x, y):\n",
    "        a_s, z_s = self.feed_forward(x)\n",
    "        d_L = (a_s[-1] - y) * sigmoid_prime(z_s[-1])\n",
    "        d_s = [0 for _ in range(len(self.weights))]\n",
    "        d_s[-1] = d_L\n",
    "        \n",
    "        # Propogate the error backwards\n",
    "        for i in reversed(range(len(d_s))-1):\n",
    "            d_l = ((self.weights[i+1].T) @ d_s[i+1]) * sigmoid_prime(z_s[i])\n",
    "            d_s[i] = d_l\n",
    "\n",
    "        nabla_b = d_s\n",
    "        nabla_w = [d_s[i] @ (a_s[i].T) for i in range(len(d_s))]\n",
    "\n",
    "        return (nabla_w, nabla_b)\n",
    "            \n",
    "    def sigmoid(self, k):\n",
    "        return 1.0 / (1.0 + np.exp(-k))\n",
    "\n",
    "    def sigmoid_prime(self, z):\n",
    "        return self.sigmoid(z)*(1-self.sigmoid(z))\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
